import os
import argparse
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.nn.functional as F
from scipy.stats import pearsonr, entropy
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from tqdm import tqdm

# Import Model Factories
try:
    from models.COMET import get_COMET
    from models.orthogonal import get_Orthogonal
    from models.COMET_center import get_COMET_center
except ImportError:
    from COMET import get_COMET
    from models.orthogonal import get_Orthogonal
    from models.COMET_center import get_COMET_center

from loading_datasets import get_data_loaders

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
CLASSES = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

def load_model(model_name, checkpoint_path, args):
    if model_name == 'COMET_model':
        model = get_COMET(args.dataset, args.neurons, args.neurons, args.neurons, 10, args.topk, args.norm, args.activation)
    elif model_name == 'Orthogonal':
        model = get_Orthogonal(args.dataset, args.neurons, args.neurons, args.neurons, 10, args.topk, args.norm, args.activation)
    elif model_name == 'COMET_center':
        model = get_COMET_center(args.dataset, args.neurons, args.neurons, args.neurons, 10, args.topk, args.norm, args.activation)
    else:
        raise ValueError(f"Unknown model: {model_name}")
    
    state_dict = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()
    return model

# ==============================================================================
# 0. Helper: Extract Masks Correctly via Forward Pass
# ==============================================================================
def get_layer_masks(model, x):
    """
    Runs a full forward pass and extracts the binary masks generated by the model.
    This fixes the shape mismatch error by ensuring deep layers receive the correct
    activations from previous layers.
    """
    with torch.no_grad():
        _ = model(x)
    
    masks = {}
    # COMET models store masks in self.layer_X_mask during forward pass
    if hasattr(model, 'layer_1_mask') and model.layer_1_mask is not None:
        masks['spec_1'] = model.layer_1_mask.clone()
    if hasattr(model, 'layer_2_mask') and model.layer_2_mask is not None:
        masks['spec_2'] = model.layer_2_mask.clone()
    if hasattr(model, 'layer_3_mask') and model.layer_3_mask is not None:
        masks['spec_3'] = model.layer_3_mask.clone()
    
    # Note: spec_4 is typically unused in the provided COMET code (output layer),
    # so we don't look for it to avoid errors.
    return masks

# ==============================================================================
# 1. Standard Metrics
# ==============================================================================
def plot_learning_curves(base_dir, save_path):
    print("Generating Learning Curves...")
    agg_path = os.path.join(base_dir, "aggregated_metrics.pkl")
    if not os.path.exists(agg_path):
        print(f"Warning: {agg_path} not found. Skipping curves.")
        return

    with open(agg_path, "rb") as f:
        data = pickle.load(f)

    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    for ax, metric, title in zip(axes, ['loss', 'acc'], ['Loss', 'Accuracy']):
        for phase in ['train', 'val']:
            key = f"{phase}_{metric}"
            if key in data:
                arr = np.array(data[key])
                if arr.ndim == 2:
                    mean = arr.mean(axis=0)
                    std = arr.std(axis=0)
                    epochs = range(1, len(mean) + 1)
                    ax.plot(epochs, mean, label=key)
                    ax.fill_between(epochs, mean-std, mean+std, alpha=0.2)
        ax.set_title(title)
        ax.legend()
        ax.grid(True, alpha=0.3)

    plt.savefig(save_path)
    print(f"Saved Curves: {save_path}")

def analyze_predictions(base_dir, save_cm, save_report, save_acc_plot):
    print("Analyzing Aggregated Predictions...")
    all_y_true, all_y_pred = [], []
    
    seed_files = [f for f in os.listdir(base_dir) if f.endswith('_detailed.pkl')]
    for f in seed_files:
        with open(os.path.join(base_dir, f), "rb") as pkl:
            res = pickle.load(pkl)
            all_y_true.append(res['y_true'])
            all_y_pred.append(res['y_pred'])
            
    if not all_y_true: return

    y_true = np.concatenate(all_y_true)
    y_pred = np.concatenate(all_y_pred)

    report = classification_report(y_true, y_pred, target_names=CLASSES, digits=3)
    with open(save_report, "w") as f: f.write(report)

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)
    plt.title("Aggregated Confusion Matrix")
    plt.savefig(save_cm)
    plt.close()

    # Ship Sink Metric
    plane_idx, ship_idx = 0, 8
    total_planes = cm[plane_idx, :].sum()
    confusion_rate = (cm[plane_idx, ship_idx] / total_planes) * 100
    print(f"\n>>> SHIP SINK DIAGNOSTIC: {confusion_rate:.2f}% of Planes misclassified as Ships <<<")

    # Per-Class Acc
    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    plt.figure(figsize=(12, 6))
    # Fix for seaborn depreciation warning: pass hue=x or use standard bar
    sns.barplot(x=CLASSES, y=cm_norm.diagonal(), hue=CLASSES, palette="viridis", legend=False)
    plt.title("Per-Class Accuracy")
    plt.ylim(0, 1.0)
    plt.savefig(save_acc_plot)
    plt.close()

# ==============================================================================
# 2. Semantic Sensitivity (CS230 Perturbations)
# ==============================================================================
class PerturbationProbe:
    def __init__(self, device):
        self.device = device
        kernel = torch.tensor([[-1., -1., -1.], [-1., 8., -1.], [-1., -1., -1.]])
        self.kernel = kernel.view(1, 1, 3, 3).repeat(3, 1, 1, 1).to(device)

    def perturb_background(self, x):
        B, C, H, W = x.shape
        mask = torch.ones_like(x)
        start_h, start_w = H//2 - 8, W//2 - 8
        mask[:, :, start_h:start_h+16, start_w:start_w+16] = 0
        return x * (1 - mask) + torch.randn_like(x) * mask

    def perturb_object(self, x):
        x_occ = x.clone()
        start_h, start_w = x.shape[2]//2 - 8, x.shape[3]//2 - 8
        x_occ[:, :, start_h:start_h+16, start_w:start_w+16] = 0.5
        return x_occ

    def perturb_grayscale(self, x):
        weights = torch.tensor([0.299, 0.587, 0.114]).view(1, 3, 1, 1).to(self.device)
        return (x * weights).sum(dim=1, keepdim=True).repeat(1, 3, 1, 1)

    def perturb_highpass(self, x):
        return F.conv2d(x, self.kernel, padding=1, groups=3)

def analyze_semantic_sensitivity(model, loader, layers, save_dir):
    print(f"Running Semantic Sensitivity Probe on {layers}...")
    probe = PerturbationProbe(device)
    perts = {'Background': probe.perturb_background, 'Object': probe.perturb_object, 
             'Grayscale': probe.perturb_grayscale, 'HighPass': probe.perturb_highpass}
    
    x_orig, _ = next(iter(loader))
    x_orig = x_orig[:100].to(device)
    
    results = {l: {p: 0 for p in perts} for l in layers}
    
    # Get original masks correctly via forward pass
    masks_orig = get_layer_masks(model, x_orig)

    for p_name, p_func in perts.items():
        x_pert = p_func(x_orig)
        masks_pert = get_layer_masks(model, x_pert)
        
        for layer_name in layers:
            if layer_name in masks_orig and layer_name in masks_pert:
                m_orig = masks_orig[layer_name]
                m_pert = masks_pert[layer_name]
                sim = F.cosine_similarity(m_orig, m_pert, dim=1).mean().item()
                results[layer_name][p_name] = sim

    # Plot
    fig, axes = plt.subplots(1, len(layers), figsize=(6*len(layers), 5), squeeze=False)
    for i, layer in enumerate(layers):
        if layer not in results: continue
        ax = axes[0, i]
        vals = results[layer]
        ax.bar(vals.keys(), vals.values(), color=['skyblue', 'salmon', 'lightgreen', 'orange'])
        ax.set_ylim(0, 1.1)
        ax.set_title(f"Sensitivity: {layer}")
        ax.set_ylabel("Mask Similarity (Invariant)")
        for j, v in enumerate(vals.values()):
            ax.text(j, v+0.02, f"{v:.2f}", ha='center')
    
    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, "analysis_sensitivity.png"))
    print("Saved Sensitivity Analysis.")

# ==============================================================================
# 3. Topology & Representation Rank
# ==============================================================================
def analyze_topology_and_rank(model, loader, layers, save_dir):
    print("Running Topology & Rank Analysis...")
    
    data = {l: {'masks': [], 'inputs': []} for l in layers}
    activations = {}
    def get_activation(name):
        def hook(model, input, output):
            activations[name] = output.detach()
        return hook

    # Register hooks on backbone layers to catch activations for Rank Analysis
    layer_map = {'spec_1': 'fc1', 'spec_2': 'fc2', 'spec_3': 'fc3'}
    handles = []
    for s_name in layers:
        if s_name in layer_map and hasattr(model, layer_map[s_name]):
            fc_layer = getattr(model, layer_map[s_name])
            handles.append(fc_layer.register_forward_hook(get_activation(s_name)))

    count = 0
    ranks = {l: [] for l in layers}
    
    with torch.no_grad():
        for x, _ in tqdm(loader, desc="Scanning Topology", leave=False):
            x = x.to(device)
            # Run forward pass to trigger hooks and generate masks
            _ = model(x)
            
            # Extract masks securely
            masks = get_layer_masks(model, x) # Note: this re-runs forward if not cached, but here we just rely on state or re-run.
            # actually get_layer_masks runs forward. Let's optimize:
            # We already ran model(x) to trigger backbone hooks. 
            # We can grab masks directly from model state now.
            
            x_flat = x.view(x.size(0), -1)
            
            for layer_name in layers:
                # 1. Topology Data
                mask_attr = None
                if layer_name == 'spec_1': mask_attr = 'layer_1_mask'
                elif layer_name == 'spec_2': mask_attr = 'layer_2_mask'
                elif layer_name == 'spec_3': mask_attr = 'layer_3_mask'
                
                if mask_attr and hasattr(model, mask_attr):
                    mask = getattr(model, mask_attr)
                    if count < 2000:
                        data[layer_name]['masks'].append(mask.cpu())
                        data[layer_name]['inputs'].append(x_flat.cpu())

                # 2. Effective Rank
                if layer_name in activations:
                    act = activations[layer_name]
                    try:
                        _, S, _ = torch.svd(act)
                        S_norm = S / S.sum()
                        eff_rank = torch.exp(torch.sum(-S_norm * torch.log(S_norm + 1e-9))).item()
                        ranks[layer_name].append(eff_rank)
                    except: pass
            
            count += x.size(0)
            if count >= 2000: break
            
    for h in handles: h.remove()
    
    # Plot Topology
    valid_layers = [l for l in layers if data[l]['inputs']]
    if valid_layers:
        fig, axes = plt.subplots(1, len(valid_layers), figsize=(5*len(valid_layers), 5), squeeze=False)
        for i, layer_name in enumerate(valid_layers):
            X = torch.cat(data[layer_name]['inputs'])[:500].to(device)
            M = torch.cat(data[layer_name]['masks'])[:500].to(device)
            
            x_sim = torch.mm(F.normalize(X), F.normalize(X).t())
            m_sim = torch.mm(F.normalize(M), F.normalize(M).t())
            
            triu = torch.triu_indices(len(X), len(X), offset=1)
            x_vals = x_sim[triu[0], triu[1]].cpu().numpy()
            m_vals = m_sim[triu[0], triu[1]].cpu().numpy()
            
            ax = axes[0, i]
            ax.scatter(x_vals, m_vals, alpha=0.1, s=2)
            if len(x_vals) > 1:
                m, b = np.polyfit(x_vals, m_vals, 1)
                ax.plot(x_vals, m*x_vals+b, 'r--')
                ax.set_title(f"{layer_name} Topology (Slope={m:.2f})")
            ax.set_xlabel("Input Sim")
        axes[0,0].set_ylabel("Mask Sim")
        plt.tight_layout()
        plt.savefig(os.path.join(save_dir, "analysis_topology.png"))
    
    # Plot Rank
    if any(ranks.values()):
        plt.figure(figsize=(10, 6))
        rank_means = [np.mean(ranks[l]) for l in layers if ranks[l]]
        rank_layers = [l for l in layers if ranks[l]]
        plt.bar(rank_layers, rank_means, color='teal')
        plt.title("Effective Rank of Backbone Activations")
        plt.savefig(os.path.join(save_dir, "analysis_ranks.png"))
        print("Saved Topology & Rank Analysis.")

# ==============================================================================
# 4. Ship Sink Visualization (t-SNE)
# ==============================================================================
def visualize_ship_sink(model, loader, save_path):
    print("Generating Ship-Sink t-SNE...")
    activations = []
    labels = []
    hook_data = {}
    def hook(m, i, o): hook_data['out'] = o.detach().cpu()
    
    if hasattr(model, 'fc3'): handle = model.fc3.register_forward_hook(hook)
    else: handle = model.register_forward_hook(hook)
    
    with torch.no_grad():
        for x, y in loader:
            _ = model(x.to(device))
            if 'out' in hook_data:
                activations.append(hook_data['out'])
                labels.append(y)
            if len(activations) * x.size(0) > 1000: break
            
    handle.remove()
    if not activations: return

    X = torch.cat(activations).numpy()
    Y = torch.cat(labels).numpy()
    
    if X.shape[1] > 50:
        X = PCA(n_components=50).fit_transform(X)
    
    # Use higher perplexity for better global structure
    tsne = TSNE(n_components=2, perplexity=30, random_state=42)
    X_emb = tsne.fit_transform(X)
    
    plt.figure(figsize=(10, 8))
    other_mask = ~np.isin(Y, [0, 8])
    plt.scatter(X_emb[other_mask, 0], X_emb[other_mask, 1], c='lightgray', alpha=0.3, label='Others', s=10)
    plt.scatter(X_emb[Y==0, 0], X_emb[Y==0, 1], c='blue', label='Plane', s=20, alpha=0.8)
    plt.scatter(X_emb[Y==8, 0], X_emb[Y==8, 1], c='red', label='Ship', s=20, alpha=0.8)
    plt.legend()
    plt.title("t-SNE of Penultimate Layer: Plane vs Ship")
    plt.savefig(save_path)
    print(f"Saved t-SNE: {save_path}")

# ==============================================================================
# 5. Gradient & Activation Health
# ==============================================================================
def check_health(model, train_loader, criterion, save_dir):
    print("Checking Gradient & Activation Health...")
    model.train()
    x, y = next(iter(train_loader))
    model.zero_grad()
    
    # Safe forward for train mode
    try: out = model(x.to(device))
    except TypeError: out = model(x.to(device), 'train')
        
    loss = criterion(out, y.to(device))
    loss.backward()
    
    grads = {n: p.grad.abs().cpu().numpy() for n, p in model.named_parameters() 
             if p.grad is not None and ('fc' in n or 'backbone' in n)}
    
    activations = {}
    def get_act(n): return lambda m, i, o: activations.update({n: o.detach().abs().cpu().numpy()})
    
    handles = []
    for n, m in model.named_modules():
        if isinstance(m, nn.Linear) and ('fc' in n or 'backbone' in n):
            handles.append(m.register_forward_hook(get_act(n)))
            
    with torch.no_grad():
        if hasattr(model, 'forward'):
             try: model(x.to(device))
             except: model(x.to(device), 'train')

    for h in handles: h.remove()
    
    if not grads: return
    
    # Plotting
    cols = len(grads)
    fig, axes = plt.subplots(2, cols, figsize=(4*cols, 8))
    if cols == 1: axes = axes.reshape(2, 1)
    
    sorted_keys = sorted(grads.keys())
    for i, name in enumerate(sorted_keys):
        # Grad
        ax = axes[0, i]
        ax.hist(grads[name].flatten(), bins=30, color='red', alpha=0.7, log=True)
        ax.set_title(f"Grads: {name}")
        
        # Act
        ax = axes[1, i]
        clean_name = name.replace('.weight', '').replace('.bias', '')
        if clean_name in activations:
            ax.hist(activations[clean_name].flatten(), bins=30, color='blue', alpha=0.7, log=True)
            ax.set_title(f"Acts: {clean_name}")
        else:
            ax.text(0.5, 0.5, "No Data", ha='center')

    plt.tight_layout()
    plt.savefig(os.path.join(save_dir, "analysis_health_histograms.png"))
    print("Saved Health Histograms.")

# ==============================================================================
# Main
# ==============================================================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, required=True)
    parser.add_argument("--base_dir", type=str, required=True)
    parser.add_argument("--dataset", type=str, default="cifar10")
    parser.add_argument("--neurons", type=int, default=3000)
    parser.add_argument("--topk", type=float, default=0.5)
    parser.add_argument("--norm", type=str, default=None)
    parser.add_argument("--activation", type=str, default="softplus")
    
    args = parser.parse_args()
    
    # 1. Standard Metrics
    plot_learning_curves(args.base_dir, os.path.join(args.base_dir, "analysis_learning_curves.png"))
    analyze_predictions(
        args.base_dir, 
        os.path.join(args.base_dir, "analysis_confusion_matrix.png"),
        os.path.join(args.base_dir, "analysis_report.txt"),
        os.path.join(args.base_dir, "analysis_class_acc.png")
    )
    
    # 2. Deep Diagnostics
    checkpoint = os.path.join(args.base_dir, "seed_0_model.pth")
    if os.path.exists(checkpoint):
        print(f"\nLoading Seed 0 from {checkpoint}")
        model = load_model(args.model, checkpoint, args)
        train_loader, val_loader, _, _ = get_data_loaders(args.dataset, 128, False)
        
        # Determine valid target layers (spec_1, spec_2, etc.)
        # Filter out spec_4 as it is usually the output readout and doesn't generate a mask in standard COMET
        target_layers = ['spec_1', 'spec_2', 'spec_3']
        print(f"Targeting layers: {target_layers}")
        
        # A. Semantic Sensitivity
        analyze_semantic_sensitivity(model, val_loader, target_layers, args.base_dir)
        
        # B. Topology & Rank
        analyze_topology_and_rank(model, val_loader, target_layers, args.base_dir)
        
        # C. Ship-Sink t-SNE
        visualize_ship_sink(model, val_loader, os.path.join(args.base_dir, "analysis_tsne.png"))
        
        # D. Health Check
        check_health(model, train_loader, nn.CrossEntropyLoss(), args.base_dir)
            
    else:
        print("Seed 0 checkpoint not found. Skipping deep diagnostics.")

if __name__ == "__main__":
    main()